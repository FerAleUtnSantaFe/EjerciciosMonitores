{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FerAleUtnSantaFe/EjerciciosMonitores/blob/master/tutorial_llms_groq.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "92a0111f",
      "metadata": {
        "id": "92a0111f"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade groq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a005984d",
      "metadata": {
        "id": "a005984d"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from groq import Groq\n",
        "from google.colab import userdata\n",
        "\n",
        "# Configurar la API Key de Groq (reemplazar con tu clave)\n",
        "GROQ_API_KEY = userdata.get('GROQ_API_KEY')  # <-- Reemplazá con tu clave real\n",
        "client = Groq(api_key=GROQ_API_KEY)\n",
        "\n",
        "modelo = \"llama-3.3-70b-versatile\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8bc25ba7",
      "metadata": {
        "id": "8bc25ba7"
      },
      "source": [
        "## 1. Ejemplo básico de un prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4ff0a58",
      "metadata": {
        "id": "f4ff0a58"
      },
      "outputs": [],
      "source": [
        "prompt = \"¿Cuál es la capital de Argentina?\"\n",
        "\n",
        "respuesta = client.chat.completions.create(\n",
        "    model=modelo,\n",
        "    messages=[\n",
        "        {\"role\": \"user\", \"content\": prompt}\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(respuesta.choices[0].message.content)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2f4ee3ad",
      "metadata": {
        "id": "2f4ee3ad"
      },
      "source": [
        "## 2. Práctica: Límite de tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "153b573e",
      "metadata": {
        "id": "153b573e"
      },
      "outputs": [],
      "source": [
        "prompt = \"Contame una historia muy larga sobre un dragón y un robot.\"\n",
        "\n",
        "for max_tokens in [50, 100, 300]:\n",
        "    print(f\"\\n--- Máximo de tokens: {max_tokens} ---\")\n",
        "    respuesta = client.chat.completions.create(\n",
        "        model=modelo,\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        max_tokens=max_tokens\n",
        "    )\n",
        "    print(respuesta.choices[0].message.content)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c965dc74",
      "metadata": {
        "id": "c965dc74"
      },
      "source": [
        "## 3. Práctica: Uso de temperature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8383877c",
      "metadata": {
        "id": "8383877c"
      },
      "outputs": [],
      "source": [
        "prompt = \"Completá la frase: En una noche oscura y silenciosa, el gato se subió al techo y...\"\n",
        "\n",
        "temperaturas = [0.0, 0.3, 0.7, 1.0, 2.0]\n",
        "\n",
        "for temp in temperaturas:\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"llama3-8b-8192\",\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": prompt\n",
        "            }\n",
        "        ],\n",
        "        temperature=temp,\n",
        "        max_tokens=60\n",
        "    )\n",
        "\n",
        "    print(f\"\\n--- Temperature {temp} ---\\n{response.choices[0].message.content}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b47c99c0",
      "metadata": {
        "id": "b47c99c0"
      },
      "source": [
        "## 4. Práctica: Uso de top-k y top-p"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bff74358",
      "metadata": {
        "id": "bff74358"
      },
      "outputs": [],
      "source": [
        "prompt = \"Inventá un chiste corto sobre programadores.\"\n",
        "\n",
        "respuesta = client.chat.completions.create(\n",
        "    model=modelo,\n",
        "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "    top_p=0.9\n",
        ")\n",
        "print(respuesta.choices[0].message.content)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "19a9b410",
      "metadata": {
        "id": "19a9b410"
      },
      "source": [
        "## 6. Técnicas de prompting"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# System prompt\n",
        "response = client.chat.completions.create(\n",
        "    model=\"llama3-8b-8192\",\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"Sos un profesor universitario que responde de forma clara, concisa y con ejemplos.\"\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"Explicá qué es una red neuronal.\"\n",
        "        }\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)\n"
      ],
      "metadata": {
        "id": "9BQFdkQ0asVn"
      },
      "id": "9BQFdkQ0asVn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Role prompting\n",
        "response = client.chat.completions.create(\n",
        "    model=\"llama3-8b-8192\",\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"Actuá como un historiador experto. ¿Cómo afectó la Revolución Francesa al resto del mundo?\"\n",
        "        }\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)\n"
      ],
      "metadata": {
        "id": "ELQHf6R2atYF"
      },
      "id": "ELQHf6R2atYF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Contextual prompting\n",
        "contexto = \"La empresa X fabrica bicicletas eléctricas con diseño ecológico.\"\n",
        "pregunta = \"¿Qué produce la empresa X?\"\n",
        "print(client.chat.completions.create(model=modelo, messages=[{\"role\": \"user\", \"content\": contexto + \"\\n\" + pregunta}]).choices[0].message.content)\n",
        "\n"
      ],
      "metadata": {
        "id": "Sjdo2TdxauZC"
      },
      "id": "Sjdo2TdxauZC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33b0dace",
      "metadata": {
        "id": "33b0dace"
      },
      "outputs": [],
      "source": [
        "# Zero-shot\n",
        "print(client.chat.completions.create(model=modelo, messages=[{\"role\": \"user\", \"content\": \"Clasificá el siguiente texto como positivo o negativo: 'Me encantó el producto.'\"}]).choices[0].message.content)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# One-shot\n",
        "response = client.chat.completions.create(\n",
        "    model=\"llama3-8b-8192\",\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"Sos un asistente que transforma frases informales en versiones formales, manteniendo el mismo significado.\"\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"\"\"Ejemplo:\n",
        "Frase informal: Che, ¿me podés dar una mano con esto?\n",
        "Frase formal: ¿Serías tan amable de ayudarme con esto?\n",
        "\n",
        "Nueva frase:\n",
        "Frase informal: Pintó irnos temprano del laburo.\n",
        "Frase formal:\"\"\"\n",
        "        }\n",
        "    ],\n",
        "    temperature=0.3,\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "id": "VTf9us-rapj3"
      },
      "id": "VTf9us-rapj3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Few-shot\n",
        "response = client.chat.completions.create(\n",
        "    model=\"llama3-8b-8192\",\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"Sos un modelo que clasifica reseñas de películas como POSITIVA, NEUTRAL o NEGATIVA. Respondé solo con la categoría correspondiente.\"\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"\"\"Clasificá las siguientes reseñas:\n",
        "Reseña: \"Una obra maestra visual y emocional.\"\n",
        "Sentimiento: POSITIVA\n",
        "\n",
        "Reseña: \"La película fue... meh. Ni buena ni mala, simplemente aburrida.\"\n",
        "Sentimiento: NEUTRAL\n",
        "\n",
        "Reseña: \"No la recomiendo. Mal actuada y con un guion pobre.\"\n",
        "Sentimiento: NEGATIVA\n",
        "\n",
        "Reseña: \"Una experiencia cinematográfica intensa que te deja pensando.\"\n",
        "Sentimiento:\"\"\"\n",
        "        }\n",
        "    ],\n",
        "    temperature=0.2,\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "id": "QvzpOAeDxQIf"
      },
      "id": "QvzpOAeDxQIf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# System, Role and Contextual prompting\n",
        "response = client.chat.completions.create(\n",
        "    model=\"llama3-8b-8192\",\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"Sos un profesor de programación que responde con ejemplos simples y claros.\"\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"\"\"\n",
        "Actuá como si estuvieras dando una clase de introducción a estudiantes que no saben programar.\n",
        "\n",
        "Contexto:\n",
        "Queremos explicar qué es una variable en Python.\n",
        "\n",
        "Explicá el concepto con un ejemplo.\n",
        "\"\"\"\n",
        "        }\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "id": "4vyyRDqp_QlW"
      },
      "id": "4vyyRDqp_QlW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step-back prompting\n",
        "# Prompt SIN step-back\n",
        "# sin_stepback = client.chat.completions.create(\n",
        "#     model=\"llama3-8b-8192\",\n",
        "#     messages=[\n",
        "#         {\n",
        "#             \"role\": \"user\",\n",
        "#             \"content\": \"Dame una idea de negocio innovadora para resolver problemas de transporte urbano.\"\n",
        "#         }\n",
        "#     ]\n",
        "# )\n",
        "\n",
        "# print(\"🟡 Resultado SIN Step-back:\\n\")\n",
        "# print(sin_stepback.choices[0].message.content)\n",
        "\n",
        "# Prompt CON step-back prompting\n",
        "con_stepback = client.chat.completions.create(\n",
        "    model=\"llama3-8b-8192\",\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"\"\"\n",
        "Antes de darme una idea de negocio, pensá:\n",
        "1. ¿Cuáles son los principales problemas actuales del transporte urbano?\n",
        "2. ¿Qué necesidades no están bien cubiertas?\n",
        "3. ¿Qué soluciones tecnológicas podrían aplicarse?\n",
        "Ahora sí, proponé una idea de negocio innovadora y explicá por qué puede funcionar.\n",
        "\"\"\"\n",
        "        }\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(\"\\n🟢 Resultado CON Step-back:\\n\")\n",
        "print(con_stepback.choices[0].message.content)\n"
      ],
      "metadata": {
        "id": "YfFF6PbaavkI"
      },
      "id": "YfFF6PbaavkI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chain of Thought (CoT)\n",
        "print(client.chat.completions.create(model=modelo, messages=[{\"role\": \"user\", \"content\": \"Si Juan tiene 3 manzanas y compra 2 más, ¿cuántas tiene ahora? Explicá paso a paso.\"}]).choices[0].message.content)\n",
        "\n"
      ],
      "metadata": {
        "id": "CSJdkcvJawnR"
      },
      "id": "CSJdkcvJawnR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Self-consistency\n",
        "\n",
        "# Prompt con Chain of Thought\n",
        "prompt = \"\"\"Resolvé este problema paso a paso:\n",
        "Si un tren sale de Córdoba a las 8:00 am y viaja a 80 km/h, ¿a qué hora llega a Rosario, que está a 320 km de distancia?\"\"\"\n",
        "\n",
        "respuestas = []\n",
        "\n",
        "# Generamos 5 respuestas diferentes\n",
        "for i in range(5):\n",
        "    res = client.chat.completions.create(\n",
        "        model=\"llama3-8b-8192\",\n",
        "        temperature=0.7,\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        "    )\n",
        "    respuestas.append(res.choices[0].message.content)\n",
        "\n",
        "# Mostrar todas las respuestas\n",
        "for i, r in enumerate(respuestas, start=1):\n",
        "    print(f\"🔁 Razonamiento {i}:\\n{r}\\n{'-'*60}\")"
      ],
      "metadata": {
        "id": "AFm9WnsAaxeb"
      },
      "id": "AFm9WnsAaxeb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "8a0018db",
      "metadata": {
        "id": "8a0018db"
      },
      "source": [
        "## 7. Generar código en JavaScript"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fdc46072",
      "metadata": {
        "id": "fdc46072"
      },
      "outputs": [],
      "source": [
        "prompt = \"Escribí una función en JavaScript que calcule el factorial de un número.\"\n",
        "\n",
        "respuesta = client.chat.completions.create(\n",
        "    model=modelo,\n",
        "    messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        ")\n",
        "print(respuesta.choices[0].message.content)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3713b23d",
      "metadata": {
        "id": "3713b23d"
      },
      "source": [
        "## 8. Explicar código en Python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86191097",
      "metadata": {
        "id": "86191097"
      },
      "outputs": [],
      "source": [
        "codigo = '''def contar_palabras(texto):\n",
        "    palabras = texto.split()\n",
        "    return len(palabras)'''\n",
        "\n",
        "prompt = f\"Explicá qué hace este código en Python:\\n\\n{codigo}\"\n",
        "\n",
        "respuesta = client.chat.completions.create(\n",
        "    model=modelo,\n",
        "    messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        ")\n",
        "print(respuesta.choices[0].message.content)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "74291e3a",
      "metadata": {
        "id": "74291e3a"
      },
      "source": [
        "## 9. Traducir de JavaScript a Python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9333f97",
      "metadata": {
        "id": "c9333f97"
      },
      "outputs": [],
      "source": [
        "js_code = \"function sumar(a, b) { return a + b; }\"\n",
        "prompt = f\"Traducí este código JavaScript a Python:\\n\\n{js_code}\"\n",
        "\n",
        "respuesta = client.chat.completions.create(\n",
        "    model=modelo,\n",
        "    messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        ")\n",
        "print(respuesta.choices[0].message.content)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "69e9d8bc",
      "metadata": {
        "id": "69e9d8bc"
      },
      "source": [
        "## 10. Devolver JSON con schema"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9cff904f",
      "metadata": {
        "id": "9cff904f"
      },
      "outputs": [],
      "source": [
        "schema = {\n",
        "  \"type\": \"object\",\n",
        "  \"properties\": {\n",
        "    \"nombre\": {\"type\": \"string\"},\n",
        "    \"precio\": {\"type\": \"number\"},\n",
        "    \"stock\": {\"type\": \"integer\"},\n",
        "    \"categoria\": {\"type\": \"string\"}\n",
        "  },\n",
        "  \"required\": [\"nombre\", \"precio\", \"stock\", \"categoria\"]\n",
        "}\n",
        "\n",
        "prompt = f\"Generá un producto de ejemplo que cumpla con este schema JSON:\\n\\n{schema}\"\n",
        "\n",
        "respuesta = client.chat.completions.create(\n",
        "    model=modelo,\n",
        "    messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        ")\n",
        "print(respuesta.choices[0].message.content)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}